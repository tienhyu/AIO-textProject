{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ec02bf1ff3c4f5f9aeccaf5239bce90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beefd319078d4495b70e261898b4c128",
              "IPY_MODEL_65ba8077a11043888d18229640daa6cb",
              "IPY_MODEL_af25bf1f5d80404cbe9334a8901731b8"
            ],
            "layout": "IPY_MODEL_65ef198258454b4f82a49ede464b85eb"
          }
        },
        "beefd319078d4495b70e261898b4c128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6cc6cde80924140962bdcb77ee5da3e",
            "placeholder": "​",
            "style": "IPY_MODEL_805dd123072749e78bc911c394a9e887",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "65ba8077a11043888d18229640daa6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c58d0aec03204757a0b30a1d4bf49b60",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fef44f0874054afc9f2bfea2225789b3",
            "value": 2
          }
        },
        "af25bf1f5d80404cbe9334a8901731b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_141bc3814ab04521869c811955a3cffe",
            "placeholder": "​",
            "style": "IPY_MODEL_4fcf2eae92bc4bc7805702a8ebdba741",
            "value": " 2/2 [01:04&lt;00:00, 29.52s/it]"
          }
        },
        "65ef198258454b4f82a49ede464b85eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6cc6cde80924140962bdcb77ee5da3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805dd123072749e78bc911c394a9e887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c58d0aec03204757a0b30a1d4bf49b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef44f0874054afc9f2bfea2225789b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "141bc3814ab04521869c811955a3cffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fcf2eae92bc4bc7805702a8ebdba741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Download dataset**"
      ],
      "metadata": {
        "id": "cGHtMEkXVEZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1lWuq0COKnU9mCfMvTEq54DBLgAh3yYDx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEsGy4qAVKN_",
        "outputId": "2d15d7a5-9039-447d-9f51-bd715d5b87e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lWuq0COKnU9mCfMvTEq54DBLgAh3yYDx\n",
            "To: /content/YOLOv10_Tutorials.pdf\n",
            "\r  0% 0.00/16.6M [00:00<?, ?B/s]\r 54% 8.91M/16.6M [00:00<00:00, 74.8MB/s]\r100% 16.6M/16.6M [00:00<00:00, 102MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Install and import necessary libraries**"
      ],
      "metadata": {
        "id": "Bp92r95CVKml"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4spZ-awzoE50"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers==4.41.2\n",
        "!pip install -q bitsandbytes==0.43.1\n",
        "!pip install -q accelerate==0.31.0\n",
        "!pip install -q langchain==0.2.5\n",
        "!pip install -q langchainhub==0.1.20\n",
        "!pip install -q langchain-chroma==0.1.1\n",
        "!pip install -q langchain-community==0.2.5\n",
        "!pip install -q langchain_huggingface==0.0.3\n",
        "!pip install -q python-dotenv==1.0.1\n",
        "!pip install -q pypdf==4.2.0\n",
        "!pip install -q numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain import hub"
      ],
      "metadata": {
        "id": "3fhokpiYVB1X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Read file (PDF)**"
      ],
      "metadata": {
        "id": "46fSkjsHVZXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Loader = PyPDFLoader\n",
        "FILE_PATH = \"./YOLOv10_Tutorials.pdf\"\n",
        "loader = Loader(FILE_PATH)\n",
        "documents = loader.load()\n",
        "\n",
        "print(\"Number of pages of the document: \", len(documents))\n",
        "documents[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxqUgPrPVb1r",
        "outputId": "17851994-3a16-42af-d228-5d443897a1b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pages of the document:  20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': './YOLOv10_Tutorials.pdf', 'page': 0}, page_content='AI VIET NAM – AI COURSE 2024\\nTutorial: Phát hiện đối tượng trong ảnh với\\nYOLOv10\\nDinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui và\\nQuang-Vinh Dinh\\nNgày 20 tháng 6 năm 2024\\nI. Giới thiệu\\nObject Detection (Tạm dịch: Phát hiện đối tượng) là một bài toán cổ điển thuộc lĩnh vực\\nComputer Vision. Mục tiêu của bài toán này là tự động xác định vị trí của các đối tượng trong\\nmột tấm ảnh. Tính tới thời điểm hiện tại, đã có rất nhiều phương pháp được phát triển nhằm\\ngiải quyết hiệu quả bài toán này. Trong đó, các phương pháp thuộc họ YOLO (You Only Look\\nOnce) thu hút được sự chú ý rất lớn từ cộng đồng nghiên cứu bởi độ chính xác và tốc độ thực\\nthi mà loại mô hình này mang lại.\\nHình 1: Logo của mô hình YOLO. Ảnh: link.\\nThời gian vừa qua, Ao Wang và các cộng sự tại Đại học Thanh Hoa (Tsinghua University)\\nđã đề xuất mô hình YOLOv10 trong bài báo YOLOv10: Real-Time End-to-End Object\\nDetection [10]. Với những cải tiến mới, mô hình đã đạt được hiệu suất vượt trội hơn so với các\\nphiên bản YOLO trước đó ở các khía cạnh khác nhau, tăng cường khả năng phát hiện đối tượng\\ntheo thời gian thực (real-time object detection).\\n1')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Run text splitter**"
      ],
      "metadata": {
        "id": "9ZvJbLs8VhV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)"
      ],
      "metadata": {
        "id": "Gk-NrGoOVe8u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "print(\"Number of mini-documents: \", len(docs))\n",
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dksjRLCfVtt2",
        "outputId": "1c5e829b-ac7a-4f9c-e0ab-afc183ad6392"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mini-documents:  33\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': './YOLOv10_Tutorials.pdf', 'page': 0}, page_content='AI VIET NAM – AI COURSE 2024\\nTutorial: Phát hiện đối tượng trong ảnh với\\nYOLOv10\\nDinh-Thang Duong, Nguyen-Thuan Duong, Minh-Duc Bui và\\nQuang-Vinh Dinh\\nNgày 20 tháng 6 năm 2024\\nI. Giới thiệu\\nObject Detection (Tạm dịch: Phát hiện đối tượng) là một bài toán cổ điển thuộc lĩnh vực\\nComputer Vision. Mục tiêu của bài toán này là tự động xác định vị trí của các đối tượng trong\\nmột tấm ảnh. Tính tới thời điểm hiện tại, đã có rất nhiều phương pháp được phát triển nhằm\\ngiải quyết hiệu quả bài toán này. Trong đó, các phương pháp thuộc họ YOLO (You Only Look\\nOnce) thu hút được sự chú ý rất lớn từ cộng đồng nghiên cứu bởi độ chính xác và tốc độ thực\\nthi mà loại mô hình này mang lại.\\nHình 1: Logo của mô hình YOLO. Ảnh: link.\\nThời gian vừa qua, Ao Wang và các cộng sự tại Đại học Thanh Hoa (Tsinghua University)\\nđã đề xuất mô hình YOLOv10 trong bài báo YOLOv10: Real-Time End-to-End Object\\nDetection [10]. Với những cải tiến mới, mô hình đã đạt được hiệu suất vượt trội hơn so với các')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Build Embedding and Vector Database**"
      ],
      "metadata": {
        "id": "ztEmozBaVy-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO2-UeHCV9UL",
        "outputId": "78e9a7cc-e62b-498f-f7f9-aae0e3eaf4fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Create vector database and retriever**"
      ],
      "metadata": {
        "id": "tZKCPJf_V4o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = Chroma.from_documents(documents=docs,\n",
        "                                  embedding=embedding)\n",
        "\n",
        "retriever = vector_db.as_retriever()\n",
        "\n",
        "QUERY = \"YOLOv10 là gì\"\n",
        "result = retriever.invoke(QUERY)\n",
        "\n",
        "print(\"Number of relevant documents: \", len(result))\n",
        "result[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGrOcX0WTCh",
        "outputId": "4a33036d-f23d-4469-cc21-f98aa6540ab7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of relevant documents:  4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'page': 15, 'source': './YOLOv10_Tutorials.pdf'}, page_content='AI VIETNAM (AIO2024) aivietnam.edu.vn\\n1! mkdir datasets\\n2! unzip -q \"/ content / PlantDocv4 . zip\" -d \"/ content / datasets / PlantDocv4\\n/\"\\n3!rm / content / PlantDocv4 .zip\\nQuan sát thư mục giải nén, có thể thấy bộ dữ liệu này đã được gán nhãn và đưa vào format\\ncấu trúc dữ liệu training theo yêu cầu của YOLO. Vì vậy, chúng ta sẽ không cần thực hiện\\nbước chuẩn bị dữ liệu ở bài này.\\n2.Cài đặt và import các thư viện cần thiết: Tương tự như phần trước, các bạn chạy\\ncác đoạn code sau để cài đặt các gói thư viện để sử dụng được YOLOv10:\\n1!git clone https :// github .com/THU -MIG/ yolov10 .git\\n2%cd yolov10\\n3!pip install -q -r requirements .txt\\n4!pip install -e .\\n3.Khởi tạo mô hình YOLOv10: Chúng ta sẽ khởi tạo mộ hình YOLOv10 với phiên\\nbảnnano (n) từ trọng số đã được huấn luyện trên bộ dữ liệu COCO. Để tải trọng số\\nyolov10n.pt, các bạn chạy đoạn code sau:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Load Vicuna model and use the program**"
      ],
      "metadata": {
        "id": "v7FTe0XpWU1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nf4_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=nf4_config,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(\n",
        "    pipeline=model_pipeline,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "7ec02bf1ff3c4f5f9aeccaf5239bce90",
            "beefd319078d4495b70e261898b4c128",
            "65ba8077a11043888d18229640daa6cb",
            "af25bf1f5d80404cbe9334a8901731b8",
            "65ef198258454b4f82a49ede464b85eb",
            "f6cc6cde80924140962bdcb77ee5da3e",
            "805dd123072749e78bc911c394a9e887",
            "c58d0aec03204757a0b30a1d4bf49b60",
            "fef44f0874054afc9f2bfea2225789b3",
            "141bc3814ab04521869c811955a3cffe",
            "4fcf2eae92bc4bc7805702a8ebdba741"
          ]
        },
        "id": "LhKY3KaKWWQK",
        "outputId": "09cb3d6b-8045-4bac-bacb-0d6245639056"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ec02bf1ff3c4f5f9aeccaf5239bce90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Prompting with RAG**"
      ],
      "metadata": {
        "id": "vRASfeKLWYiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "USER_QUESTION1 = \"YOLOv10 là gì?\"\n",
        "output1 = rag_chain.invoke(USER_QUESTION1)\n",
        "output1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "9QVozEMxWZ4l",
        "outputId": "57e4c4ba-cfe1-4999-9909-0118528b617b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\nQuestion: YOLOv10 là gì? \\nContext: 2.Tải trọng số của pre-trained models: Để sử dụng được pre-trained models, chúng ta\\ncần tải về file trọng số (file .pt). Các bạn chạy đoạn code sau để tải về file trọng số phiên\\nbản YOLOv10n:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt\\n3.Khởi tạo mô hình: Để khởi tạo mô hình với trọng số vừa tải về, các bạn chạy đoạn code\\nsau:\\n1from ultralytics import YOLOv10\\n2\\n3model = YOLOv10 (\" yolov10n .pt\")\\n4.Tải ảnh cần dự đoán: Chúng ta sẽ test mô hình trên một ảnh bất kì. Các bạn có thể tự\\nchọn ảnh của riêng mình hoặc sử dụng ảnh tại đây. Các bạn có thể chạy đoạn code sau để\\ntải ảnh này vào colab tự động:\\n1! gdown \"1 tr9PSRRdlC2pNir7jsYugpSMG -7 v32VJ \" -O \"./ images /\"\\n13\\n\\nAI VIETNAM (AIO2024) aivietnam.edu.vn\\n1! mkdir datasets\\n2! unzip -q \"/ content / PlantDocv4 . zip\" -d \"/ content / datasets / PlantDocv4\\n/\"\\n3!rm / content / PlantDocv4 .zip\\nQuan sát thư mục giải nén, có thể thấy bộ dữ liệu này đã được gán nhãn và đưa vào format\\ncấu trúc dữ liệu training theo yêu cầu của YOLO. Vì vậy, chúng ta sẽ không cần thực hiện\\nbước chuẩn bị dữ liệu ở bài này.\\n2.Cài đặt và import các thư viện cần thiết: Tương tự như phần trước, các bạn chạy\\ncác đoạn code sau để cài đặt các gói thư viện để sử dụng được YOLOv10:\\n1!git clone https :// github .com/THU -MIG/ yolov10 .git\\n2%cd yolov10\\n3!pip install -q -r requirements .txt\\n4!pip install -e .\\n3.Khởi tạo mô hình YOLOv10: Chúng ta sẽ khởi tạo mộ hình YOLOv10 với phiên\\nbảnnano (n) từ trọng số đã được huấn luyện trên bộ dữ liệu COCO. Để tải trọng số\\nyolov10n.pt, các bạn chạy đoạn code sau:\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt\\n\\nAI VIETNAM (AIO2024) aivietnam.edu.vn\\nIV. Cài đặt chương trình và đánh giá\\nTrong phần này, nhóm sẽ trình bày cách cài đặt, sử dụng và huấn luyện YOLOv10 trên bộ dữ\\nliệu mới. Đồng thời, nhóm cũng thực hiện một thực nghiệm nhỏ nhằm so sánh hiệu suất của\\nYOLOv10 so với hai phiên bản gần nhất là YOLOv8 và YOLOv9. Môi trường lập trình nhóm\\nsử dụng là Google Colab.\\nIV.I. Cài đặt và sử dụng pre-trained model\\nMột cách nhanh chóng để sử dụng được YOLOv10 đó là sử dụng pre-trained model (mô hình đã\\nđược huấn luyện sẵn trên bộ dữ liệu COCO - một bộ dữ liệu rất lớn). Để sử dụng pre-trained\\nmodel, các bạn làm như sau:\\n1.Cài đặt các thư viện cần thiết: Tải về mã nguồn của YOLOv10 và cài đặt các thư\\nviện trong file requirements.txt bằng các chạy đoạn code sau:\\n1!git clone https :// github .com/THU -MIG/ yolov10 .git\\n2%cd yolov10\\n3!pip install -q -r requirements .txt\\n4!pip install -e .\\n2.Tải trọng số của pre-trained models: Để sử dụng được pre-trained models, chúng ta\\n\\n1! wget https :// github .com/THU -MIG/ yolov10 / releases / download /v1 .1/\\nyolov10n .pt\\nSau đó, để khởi tạo mô hình từ trọng số đã tải về, các bạn chạy đoạn code sau:\\n1from ultralytics import YOLOv10\\n2\\n3model = YOLOv10 (\" yolov10n .pt\")\\n4.Huấnluyệnmôhình: ChúngtatiếnhànhhuấnluyệnYOLOv10trênbộdữliệuPlantDoc\\nvới 100 epochs và kích thước ảnh là 640. Các bạn chạy đoạn code sau:\\n1model . train ( data =\"../ datasets / PlantDocv4 / data . yaml \",\\n2 epochs =100 ,\\n3 imgsz =640)\\n16 \\nAnswer: YOLOv10 là một phiên bản của YOLO (You Only Look Once) - một hệ thống dự đoán hình ảnh được huấn luyện sẵn trên bộ dữ liệu COCO. Phiên bản này được tạo bằng cách tải về trọng số (file.pt) từ GitHub và khởi tạo mô hình bằng cách sử dụng thư viện ultralytics.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer1 = output1.split('Answer:')[1].strip()\n",
        "answer1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "6eDP3PcNWcdT",
        "outputId": "81331af1-bb66-4c3f-8211-04a4468f529c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YOLOv10 là một phiên bản của YOLO (You Only Look Once) - một hệ thống dự đoán hình ảnh được huấn luyện sẵn trên bộ dữ liệu COCO. Phiên bản này được tạo bằng cách tải về trọng số (file.pt) từ GitHub và khởi tạo mô hình bằng cách sử dụng thư viện ultralytics.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USER_QUESTION2 = \"Hãy cho biết tác giả của YOLOv10\"\n",
        "output2 = rag_chain.invoke(USER_QUESTION2)\n",
        "output2\n",
        "answer2 = output2.split('Answer:')[1].strip()\n",
        "answer2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "vtBpbQQ7bfZ7",
        "outputId": "8175ef22-0c44-429f-c718-ed788c3ed3ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The author of YOLOv10 is not mentioned in the given context.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USER_QUESTION3 = \"Hãy cho biết ứng dụng của YOLOv10\"\n",
        "output3 = rag_chain.invoke(USER_QUESTION3)\n",
        "output3\n",
        "answer3 = output3.split('Answer:')[1].strip()\n",
        "answer3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "1a2XCy2wcDhU",
        "outputId": "a2ca38a8-4ad7-4bfc-cf50-330096fbddd0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YOLOv10 là một phiên bản của YOLO (You Only Look Once) với mức độ tối ưu hóa cao hơn so với các phiên bản trước đó. Nó có thể dự đoán các object trong các ảnh với độ chính xác cao hơn và độ trễ trong inference trong khi vẫn giữ được độ chính xác ngang hoặc hơn so với các phiên bản trước. YOLOv10 sử dụng PGI và GELAN để cải thiện độ chính xác và hiệu suất của mô hình.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}